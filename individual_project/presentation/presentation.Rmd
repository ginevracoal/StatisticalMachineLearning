---
title: Kernel approximations on large-scale problems
subtitles: Nystr√∂m method and Random Fourier features
author: Ginevra Carbone
date: "*25 Luglio 2018*"
output:
  ioslides_presentation:
  fig_width: 7
  incremental: yes
  smaller: yes
  widescreen: yes
html_document:
  toc: yes
editor_options:
  chunk_output_type: inline
always_allow_html: yes
---
                
## Introduction {.build}

Kernel methods are based on the idea of projecting data points into a high-dimensional **feature space** and searching for the optimal **separating hyperplane** in that feature space.

<!-- ![](figures/kernel_trick.png){ width=20 } -->

<div align="center">
<img src="figures/kernel_trick.png" width=600>
</div>
---

## Introduction {.build}

The main limitation of these methods is their high **computational cost**, which is at least quadratic in the number of training points, due the calculation of the kernel matrix.

Low-rank decompositions of the matrix (like **Cholesky factorization **) r





